learning rate: 0.005
batch size: 16 in mem, 64 for optimizer

number of trainable parameters: 294912
epoch 1 -> train loss: 0.47339861452011833, valid loss: 0.4585354680220286 in 831.5360054969788 seconds
	best model saved
epoch 2 -> train loss: 0.46399942575182235, valid loss: 0.4566842983563741 in 819.7386286258698 seconds
	best model saved
epoch 3 -> train loss: 0.4622441862197149, valid loss: 0.4552436957359314 in 818.5438673496246 seconds
	best model saved
epoch 4 -> train loss: 0.46098220037278675, valid loss: 0.4550679055849711 in 817.6677339076996 seconds
	best model saved
epoch 5 -> train loss: 0.45989996090389434, valid loss: 0.4548771683375041 in 816.6238434314728 seconds
	best model saved
epoch 6 -> train loss: 0.5025624587422326, valid loss: 0.5114373329480489 in 819.4968993663788 seconds
epoch 7 -> train loss: 0.4954560914947873, valid loss: 0.500063219944636 in 818.8586189746857 seconds
early stopping
Max GPU memory allocated: 7641.33 MB
test loss: 0.45705624151229857

Downloading builder script: 100%
 6.27k/6.27k [00:00<00:00, 485kB/s]

rouge scores ->
	rouge1: 0.0692597201598466
	rouge2: 0.00320983264937658
	rougeL: 0.06090753498328272
	rougeLsum: 0.06094110470315994

