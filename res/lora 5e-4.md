learning rate: 0.0005
batch size: 16 in mem, 64 for optimizer

number of trainable parameters: 294912
epoch 1 -> train loss: 0.4946800614084516, valid loss: 0.4640947761535644 in 835.7072451114655 seconds
	best model saved
epoch 2 -> train loss: 0.4687983149119786, valid loss: 0.46073092706998187 in 825.4732117652893 seconds
	best model saved
epoch 3 -> train loss: 0.4667921059245155, valid loss: 0.4592305614153544 in 826.0285637378693 seconds
	best model saved
epoch 4 -> train loss: 0.4656814431235904, valid loss: 0.45844835352897645 in 825.4785888195038 seconds
	best model saved
epoch 5 -> train loss: 0.4649713553701128, valid loss: 0.45772122279802957 in 824.8406834602356 seconds
	best model saved
epoch 6 -> train loss: 0.4642917954354059, valid loss: 0.4573219449520111 in 825.7098467350006 seconds
	best model saved
epoch 7 -> train loss: 0.46373844703038536, valid loss: 0.45664176321029665 in 826.5661528110504 seconds
	best model saved
epoch 8 -> train loss: 0.463232029960269, valid loss: 0.4562852835655212 in 826.1904599666595 seconds
	best model saved
epoch 9 -> train loss: 0.4627580926304772, valid loss: 0.4559258708159129 in 825.0971233844757 seconds
	best model saved
epoch 10 -> train loss: 0.46236234051840647, valid loss: 0.4556900429725647 in 827.1332881450653 seconds
	best model saved
Max GPU memory allocated: 13954.30 MB
test loss: 0.4577243275642395

rouge scores ->
	rouge1: 0.07770170844514344
	rouge2: 0.002804472875757597
	rougeL: 0.06969183006045648
	rougeLsum: 0.06973684030649828