learning rate: 0.005
batch size: 16 in mem, 64 for optimizer

number of trainable parameters: 9216
epoch 1 -> train loss: 0.4994375007947286, valid loss: 0.48221453102429707 in 815.0963621139526 seconds
	best model saved
epoch 2 -> train loss: 0.4840959089597066, valid loss: 0.4799154894351959 in 801.6373448371887 seconds
	best model saved
epoch 3 -> train loss: 0.4825986035210746, valid loss: 0.4784201734860738 in 800.2568061351776 seconds
	best model saved
epoch 4 -> train loss: 0.48145120516277495, valid loss: 0.4780694148540497 in 800.9054963588715 seconds
	best model saved
epoch 5 -> train loss: 0.4808654411406744, valid loss: 0.477212238629659 in 801.2288763523102 seconds
	best model saved
epoch 6 -> train loss: 0.4805207034973871, valid loss: 0.47729671343167623 in 800.7887949943542 seconds
epoch 7 -> train loss: 0.480240176427932, valid loss: 0.4764939885934194 in 800.5093445777893 seconds
	best model saved
epoch 8 -> train loss: 0.4800202933038984, valid loss: 0.4761736806233724 in 800.1025958061218 seconds
	best model saved
epoch 9 -> train loss: 0.47977011932645525, valid loss: 0.476047536611557 in 800.9706268310547 seconds
	best model saved
epoch 10 -> train loss: 0.4795603428792847, valid loss: 0.4762151846743285 in 801.6578922271729 seconds
Max GPU memory allocated: 7303.13 MB
test loss: 0.47884667523701985

Downloading builder script: 100%
 6.27k/6.27k [00:00<00:00, 477kB/s]

rouge scores ->
	rouge1: 0.10860634678854203
	rouge2: 0.008313735847146723
	rougeL: 0.09154981282335792
	rougeLsum: 0.09157618674457021

