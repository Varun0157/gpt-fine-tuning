
learning rate: 0.001
batch size: 16 in mem, 64 for optimizer

number of trainable parameters: 9216
epoch 1 -> train loss: 0.5197713677769615, valid loss: 0.4906119236151377 in 816.9197771549225 seconds
	best model saved
epoch 2 -> train loss: 0.49021726658230735, valid loss: 0.4858646264076233 in 803.4222424030304 seconds
	best model saved
epoch 3 -> train loss: 0.487506160395486, valid loss: 0.4834181858698527 in 802.9270160198212 seconds
	best model saved
epoch 4 -> train loss: 0.4860311792918614, valid loss: 0.48204016534487404 in 802.7580304145813 seconds
	best model saved
epoch 5 -> train loss: 0.4849734282720657, valid loss: 0.4809183751742045 in 804.0021073818207 seconds
	best model saved
epoch 6 -> train loss: 0.48424044615881784, valid loss: 0.4805153695742289 in 803.0116443634033 seconds
	best model saved
epoch 7 -> train loss: 0.4836884882790702, valid loss: 0.48000140372912087 in 802.3928334712982 seconds
	best model saved
epoch 8 -> train loss: 0.4831590120451791, valid loss: 0.4798490955034892 in 801.720299243927 seconds
	best model saved
epoch 9 -> train loss: 0.48273421471459527, valid loss: 0.47941497492790225 in 799.6656296253204 seconds
	best model saved
epoch 10 -> train loss: 0.48241972178504583, valid loss: 0.4786168673038483 in 800.8430573940277 seconds
	best model saved
Max GPU memory allocated: 13954.30 MB
test loss: 0.48135796944300335

rouge scores ->
	rouge1: 0.12976331886967313
	rouge2: 0.009371065328882126
	rougeL: 0.10598549463383916
	rougeLsum: 0.10604684877945367